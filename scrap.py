import facebook_scraper as fs
import pandas as pd

print("ğŸ”¥ Facebook Comment Scraper ğŸ”¥")
# âœ… Your actual cookies from Facebook (edit manually or export from browser)
cookies = {
    "c_user": "100007141636057",
    "xs": "21%3AtW04NP0R1-b_Jw%3A2%3A1742789829%3A-1%3A10456%3AnqYAVQEk_lapfA%3AAcVXkTHLHB-xBh3dK8lylA_W5jf8EUhudMVrbNCzCg"
}

# âœ… The full post URL
POST_URL = "https://www.facebook.com/bbcnews/posts/pfbid02wvyNkAxbr66hbWQpKGZLDgsZUVR45fFM3tqpReca4DRM7KsBUz2WaVa2Vo71T3bDl"


# âœ… Max comments to load
MAX_COMMENTS = 100

# âœ… Fetch the post with comments
print("â³ Fetching post...")
gen = fs.get_posts(
    post_urls=[POST_URL],
    options={
        "comments": MAX_COMMENTS,
        "progress": True,
        "allow_extra_requests": True
    }
)

try:
    post = next(gen)
except Exception as e:
    print(f"âŒ Error: {e}")
    exit()

print("\nğŸ” Available post keys:")
print(list(post.keys()))

# âœ… Extract comments
comments = post.get("comments_full", [])
print(f"\nâœ… Total comments found: {len(comments)}")

# Preview first few comments
if comments:
    print("\nğŸ“„ Comments Preview:")
    for i, c in enumerate(comments[:5], 1):
        print(f"{i}. {c.get('comment_text')}")
else:
    print("âš ï¸ No comments found or unable to scrape them.")

# âœ… Create DataFrame
comment_data = []
for comment in comments:
    comment_id = comment.get('comment_id', '')
    comment_text = comment.get('comment_text', '')
    comment_data.append({'comment_id': comment_id, 'comment_text': comment_text})


comment_df = pd.DataFrame(comment_data)

# âœ… Preview the first few rows
print("\nğŸ“„ Scraped Comments Preview:\n")
for i, row in enumerate(comment_data[:10], start=1):
    print(f"Comment #{i}")
    print(f"ID   : {row['comment_id']}")
    print(f"Text : {row['comment_text']}\n")

# # âœ… Save to CSV
# comment_df.to_csv("t1_facebook_comment.csv", index=False)
# print("âœ… Comments saved to t1_facebook_comment.csv")
